{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SaveXgboostLstmMAIN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacob130000x/Code/blob/main/SaveXgboostLstmMAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8UxDzoDCx1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e381ea-ab5f-432f-e021-4cfa49142457"
      },
      "source": [
        "pip install xgboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3UTLlxqK_iN",
        "outputId": "01cfe523-eede-4c47-b954-0d1481c42808"
      },
      "source": [
        "!pip install pmdarima"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pmdarima\n",
            "  Downloading pmdarima-1.8.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (57.4.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.4.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.29.24)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.1.5)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.24.3)\n",
            "Collecting statsmodels!=0.12.0,>=0.11\n",
            "  Downloading statsmodels-0.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 16.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19->pmdarima) (1.15.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels!=0.12.0,>=0.11->pmdarima) (0.5.2)\n",
            "Installing collected packages: statsmodels, pmdarima\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed pmdarima-1.8.3 statsmodels-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV0hFXbHSJKG"
      },
      "source": [
        "from xgboost import XGBRegressor as XBGRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot  as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "import pandas_datareader as web\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "plt.style.use('fivethirtyeight')\n",
        "import datetime\n",
        "import time\n",
        "import requests\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "from pmdarima import auto_arima\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import statsmodels as sm\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBxwidijmjtJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#stuff needed to get the data\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import time\n",
        "import requests\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsqLF4CvGpqD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a74ce46e-5840-4552-c3d2-740bfcf4f0ea"
      },
      "source": [
        "stockNames=['AIRR','APPL']\n",
        "def RunData(stockNames, iterN):\n",
        "  for currentStockName in stockNames:\n",
        "    dfStock = pd.read_csv(currentStockName + '.csv')\n",
        "    LSTMandQgBoostPred(dfStock, iterN, currentStockName )\n",
        "    DecisionTree(dfStock, iterN, currentStockName)\n",
        "    ARIMA(dfStock, iterN, currentStockName)\n",
        "    XPS(dfStock, iterN, currentStockName)\n",
        "RunData(stockNames, 2 )\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET NEWW!!! [[19.33847237]\n",
            " [19.47596931]\n",
            " [19.17150307]\n",
            " ...\n",
            " [33.44472504]\n",
            " [33.80767441]\n",
            " [33.9336586 ]]\n",
            "DATASET 3!!! [[19.33847237]\n",
            " [19.47596931]\n",
            " [19.17150307]\n",
            " [19.17641449]\n",
            " [19.31882668]\n",
            " [19.47596931]\n",
            " [19.44650459]\n",
            " [19.47596931]\n",
            " [19.53490067]\n",
            " [19.32864952]\n",
            " [19.3777523 ]\n",
            " [19.06346893]\n",
            " [18.86704063]\n",
            " [18.91615105]\n",
            " [19.25989532]\n",
            " [19.44650459]\n",
            " [19.58400726]\n",
            " [19.46615028]\n",
            " [19.06346893]\n",
            " [18.63918495]\n",
            " [18.82775497]\n",
            " [19.10275841]\n",
            " [18.70989418]\n",
            " [18.55275154]\n",
            " [18.55275154]\n",
            " [18.5920372 ]\n",
            " [18.78846741]\n",
            " [18.98489761]\n",
            " [19.01141739]\n",
            " [19.24025536]\n",
            " [19.15185928]\n",
            " [19.16954041]\n",
            " [18.8572197 ]\n",
            " [18.76882553]\n",
            " [18.71873665]\n",
            " [18.82775497]\n",
            " [18.65783691]\n",
            " [18.76882553]\n",
            " [18.63132286]\n",
            " [18.38578796]\n",
            " [18.38480759]\n",
            " [18.1009655 ]\n",
            " [18.30722046]\n",
            " [18.80811119]\n",
            " [18.65096474]\n",
            " [18.2482872 ]\n",
            " [18.07150459]\n",
            " [18.18936157]\n",
            " [18.41525459]\n",
            " [18.1009655 ]\n",
            " [18.15989685]\n",
            " [18.21882057]\n",
            " [18.46927071]\n",
            " [18.79829597]\n",
            " [18.72953415]\n",
            " [18.64114761]\n",
            " [18.58221817]\n",
            " [18.41525459]\n",
            " [18.33667946]\n",
            " [18.25810814]\n",
            " [18.73935699]\n",
            " [19.05364609]\n",
            " [19.26972008]\n",
            " [19.21079063]\n",
            " [18.98489761]\n",
            " [18.72953415]\n",
            " [18.68043137]\n",
            " [18.66078758]\n",
            " [18.77471542]\n",
            " [18.89257622]\n",
            " [18.97507477]\n",
            " [19.01436043]\n",
            " [18.92596817]\n",
            " [18.7766819 ]\n",
            " [18.8572197 ]\n",
            " [18.82775497]\n",
            " [18.97507477]\n",
            " [19.06346893]\n",
            " [19.25007629]\n",
            " [19.23043251]\n",
            " [19.41605759]\n",
            " [19.01436043]\n",
            " [18.89650345]\n",
            " [18.77864456]\n",
            " [18.51346397]\n",
            " [18.43489456]\n",
            " [18.58221817]\n",
            " [18.44471741]\n",
            " [18.38578796]\n",
            " [18.1500721 ]\n",
            " [18.35632133]\n",
            " [18.23846436]\n",
            " [18.41525459]\n",
            " [18.34649849]\n",
            " [18.26792908]\n",
            " [18.09114456]\n",
            " [17.86525345]\n",
            " [17.8308773 ]\n",
            " [17.8848896 ]\n",
            " [17.4134655 ]]\n",
            "99/99 [==============================] - 3s 2ms/step - loss: 0.1033\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1da76a9b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "BUY NOW!!!!!!!!!!!!!!!!!! 0.0\n",
            "UP PRED j\n",
            "NEW PRED COMBINED N\n",
            "COMBO Correct UP LSTM, XGBOOST, COMBINED                        0 0 0\n",
            "COMBO Correct Down LSTM, XGBOOST, COMBINED                      1 1 1\n",
            "COMBO Incorrect Pred UP Actual Down LSTM, XGBOOST, COMBINED     0 0 0\n",
            "COMBO Incorrect Pred Down Actual Up LSTM, XGBOOST, COMBINED     0 0 0\n",
            "COMBINED PERCENTAGE CORRECT LSTM, XGBOOST, COMBINED 100.0   100.0   100.0\n",
            "---------------------END-----------------------------\n",
            "LSTM PREDICTION NOT SCALED      [[18.298204]]\n",
            "XGBOOST PREDICTION NOT SCALED   [17.820606]\n",
            "--------------------------------------------------\n",
            "DATASET 3!!! [[19.33847237]\n",
            " [19.47596931]\n",
            " [19.17150307]\n",
            " [19.17641449]\n",
            " [19.31882668]\n",
            " [19.47596931]\n",
            " [19.44650459]\n",
            " [19.47596931]\n",
            " [19.53490067]\n",
            " [19.32864952]\n",
            " [19.3777523 ]\n",
            " [19.06346893]\n",
            " [18.86704063]\n",
            " [18.91615105]\n",
            " [19.25989532]\n",
            " [19.44650459]\n",
            " [19.58400726]\n",
            " [19.46615028]\n",
            " [19.06346893]\n",
            " [18.63918495]\n",
            " [18.82775497]\n",
            " [19.10275841]\n",
            " [18.70989418]\n",
            " [18.55275154]\n",
            " [18.55275154]\n",
            " [18.5920372 ]\n",
            " [18.78846741]\n",
            " [18.98489761]\n",
            " [19.01141739]\n",
            " [19.24025536]\n",
            " [19.15185928]\n",
            " [19.16954041]\n",
            " [18.8572197 ]\n",
            " [18.76882553]\n",
            " [18.71873665]\n",
            " [18.82775497]\n",
            " [18.65783691]\n",
            " [18.76882553]\n",
            " [18.63132286]\n",
            " [18.38578796]\n",
            " [18.38480759]\n",
            " [18.1009655 ]\n",
            " [18.30722046]\n",
            " [18.80811119]\n",
            " [18.65096474]\n",
            " [18.2482872 ]\n",
            " [18.07150459]\n",
            " [18.18936157]\n",
            " [18.41525459]\n",
            " [18.1009655 ]\n",
            " [18.15989685]\n",
            " [18.21882057]\n",
            " [18.46927071]\n",
            " [18.79829597]\n",
            " [18.72953415]\n",
            " [18.64114761]\n",
            " [18.58221817]\n",
            " [18.41525459]\n",
            " [18.33667946]\n",
            " [18.25810814]\n",
            " [18.73935699]\n",
            " [19.05364609]\n",
            " [19.26972008]\n",
            " [19.21079063]\n",
            " [18.98489761]\n",
            " [18.72953415]\n",
            " [18.68043137]\n",
            " [18.66078758]\n",
            " [18.77471542]\n",
            " [18.89257622]\n",
            " [18.97507477]\n",
            " [19.01436043]\n",
            " [18.92596817]\n",
            " [18.7766819 ]\n",
            " [18.8572197 ]\n",
            " [18.82775497]\n",
            " [18.97507477]\n",
            " [19.06346893]\n",
            " [19.25007629]\n",
            " [19.23043251]\n",
            " [19.41605759]\n",
            " [19.01436043]\n",
            " [18.89650345]\n",
            " [18.77864456]\n",
            " [18.51346397]\n",
            " [18.43489456]\n",
            " [18.58221817]\n",
            " [18.44471741]\n",
            " [18.38578796]\n",
            " [18.1500721 ]\n",
            " [18.35632133]\n",
            " [18.23846436]\n",
            " [18.41525459]\n",
            " [18.34649849]\n",
            " [18.26792908]\n",
            " [18.09114456]\n",
            " [17.86525345]\n",
            " [17.8308773 ]\n",
            " [17.8848896 ]\n",
            " [17.4134655 ]\n",
            " [17.32506561]]\n",
            "100/100 [==============================] - 3s 3ms/step - loss: 0.0827\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1da76f2830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "BUY NOW!!!!!!!!!!!!!!!!!! 0.0\n",
            "UP PRED x\n",
            "NEW PRED COMBINED d\n",
            "COMBO Correct UP LSTM, XGBOOST, COMBINED                        0 0 0\n",
            "COMBO Correct Down LSTM, XGBOOST, COMBINED                      1 2 2\n",
            "COMBO Incorrect Pred UP Actual Down LSTM, XGBOOST, COMBINED     1 0 0\n",
            "COMBO Incorrect Pred Down Actual Up LSTM, XGBOOST, COMBINED     0 0 0\n",
            "COMBINED PERCENTAGE CORRECT LSTM, XGBOOST, COMBINED 50.0   100.0   100.0\n",
            "---------------------END-----------------------------\n",
            "LSTM PREDICTION NOT SCALED      [[18.313015]]\n",
            "XGBOOST PREDICTION NOT SCALED   [17.387905]\n",
            "--------------------------------------------------\n",
            "dataset3 LAST POINT [0]\n",
            "x_train LAST POINT [0]\n",
            "[0]\n",
            "correct prediction Pred Down and Actual Down\n",
            "PERCENTAGE CORRECT 100.0\n",
            "I 0\n",
            "Correct UP                      0\n",
            "Correct Down                    1\n",
            "Incorrect Pred UP Actual Down   0\n",
            "Incorrect Pred Down Actual Up   0\n",
            "---------------------------------------------------------\n",
            "Prediction, Actual Result [0] [0]\n",
            "---------------------------------------------------------\n",
            "dataset3 LAST POINT [1]\n",
            "x_train LAST POINT [0]\n",
            "[1]\n",
            "correct prediction Pred UP and Actual Up\n",
            "PERCENTAGE CORRECT 100.0\n",
            "I 1\n",
            "Correct UP                      1\n",
            "Correct Down                    1\n",
            "Incorrect Pred UP Actual Down   0\n",
            "Incorrect Pred Down Actual Up   0\n",
            "---------------------------------------------------------\n",
            "Prediction, Actual Result [1] [1]\n",
            "---------------------------------------------------------\n",
            "<class 'pandas.core.series.Series'>\n",
            "0      19.338472\n",
            "1      19.475969\n",
            "2      19.171503\n",
            "3      19.176414\n",
            "4      19.318827\n",
            "         ...    \n",
            "212    16.897600\n",
            "213    16.868073\n",
            "214    16.671249\n",
            "215    16.326797\n",
            "216    16.631884\n",
            "Name: Adj Close, Length: 217, dtype: float64\n",
            "DATA RANGE 217\n",
            "[16.67124939]\n",
            "PREDICTION [16.67124939]\n",
            "DAY BEFORE 16.326797485351562\n",
            "Actual outcome  16.63188362121582\n",
            "Correct Price is going up\n",
            "PERCENTAGE CORRECT 100.0\n",
            "Correct UP                        1\n",
            "Correct Down                      0\n",
            "Incorrect Pred UP Actual Down     0\n",
            "Incorrect Pred Down Actual Up     0\n",
            "0      19.338472\n",
            "1      19.475969\n",
            "2      19.171503\n",
            "3      19.176414\n",
            "4      19.318827\n",
            "         ...    \n",
            "213    16.868073\n",
            "214    16.671249\n",
            "215    16.326797\n",
            "216    16.631884\n",
            "217    16.287432\n",
            "Name: Adj Close, Length: 218, dtype: float64\n",
            "DATA RANGE 218\n",
            "[16.32679749]\n",
            "PREDICTION [16.32679749]\n",
            "DAY BEFORE 16.63188362121582\n",
            "Actual outcome  16.287431716918945\n",
            "Correct Price is going down\n",
            "PERCENTAGE CORRECT 100.0\n",
            "Correct UP                        1\n",
            "Correct Down                      1\n",
            "Incorrect Pred UP Actual Down     0\n",
            "Incorrect Pred Down Actual Up     0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0      19.338472\n",
            "1      19.475969\n",
            "2      19.171503\n",
            "3      19.176414\n",
            "4      19.318827\n",
            "         ...    \n",
            "212    16.897600\n",
            "213    16.868073\n",
            "214    16.671249\n",
            "215    16.326797\n",
            "216    16.631884\n",
            "Name: Adj Close, Length: 217, dtype: float64\n",
            "DATA RANGE 217\n",
            "215    16.671249\n",
            "dtype: float64\n",
            "PREDICTION 215    16.671249\n",
            "dtype: float64\n",
            "DAY BEFORE TRAINING 16.326797485351562\n",
            "Actual outcome  16.63188362121582\n",
            "['215', '16.671249', 'dtype:', 'float64']\n",
            "16.671249\n",
            "16.671249\n",
            "Correct Price is going up\n",
            "PERCENTAGE CORRECT 100.0\n",
            "Correct UP                        1\n",
            "Correct Down                      0\n",
            "Incorrect Pred UP Actual Down     0\n",
            "Incorrect Pred Down Actual Up     0\n",
            "0      19.338472\n",
            "1      19.475969\n",
            "2      19.171503\n",
            "3      19.176414\n",
            "4      19.318827\n",
            "         ...    \n",
            "213    16.868073\n",
            "214    16.671249\n",
            "215    16.326797\n",
            "216    16.631884\n",
            "217    16.287432\n",
            "Name: Adj Close, Length: 218, dtype: float64\n",
            "DATA RANGE 218\n",
            "216    16.326797\n",
            "dtype: float64\n",
            "PREDICTION 216    16.326797\n",
            "dtype: float64\n",
            "DAY BEFORE TRAINING 16.63188362121582\n",
            "Actual outcome  16.287431716918945\n",
            "['216', '16.326797', 'dtype:', 'float64']\n",
            "16.326797\n",
            "16.326797\n",
            "Correct Price is going down\n",
            "PERCENTAGE CORRECT 100.0\n",
            "Correct UP                        1\n",
            "Correct Down                      1\n",
            "Incorrect Pred UP Actual Down     0\n",
            "Incorrect Pred Down Actual Up     0\n",
            "DATASET NEWW!!! [[ 10.12136364]\n",
            " [ 10.17418575]\n",
            " [ 10.25741291]\n",
            " ...\n",
            " [134.44039917]\n",
            " [133.29406738]\n",
            " [132.26734924]]\n",
            "DATASET 3!!! [[10.12136364]\n",
            " [10.17418575]\n",
            " [10.25741291]\n",
            " [10.24912071]\n",
            " [10.3225174 ]\n",
            " [10.51692009]\n",
            " [10.49204159]\n",
            " [10.57742119]\n",
            " [10.61611271]\n",
            " [10.70210552]\n",
            " [10.46163845]\n",
            " [10.40605354]\n",
            " [10.21687508]\n",
            " [10.03384113]\n",
            " [10.36336231]\n",
            " [10.48467159]\n",
            " [10.55991364]\n",
            " [10.54025936]\n",
            " [10.32190609]\n",
            " [10.42079163]\n",
            " [10.59615231]\n",
            " [10.57434654]\n",
            " [10.54732132]\n",
            " [10.64129829]\n",
            " [10.80652332]\n",
            " [10.90848255]\n",
            " [10.99938488]\n",
            " [10.8882103 ]\n",
            " [10.95915508]\n",
            " [11.03071213]\n",
            " [11.05282307]\n",
            " [11.15201664]\n",
            " [11.00368404]\n",
            " [10.76598358]\n",
            " [10.39898968]\n",
            " [10.52214146]\n",
            " [10.53012276]\n",
            " [10.69227695]\n",
            " [10.84736729]\n",
            " [10.72759342]\n",
            " [10.81389141]\n",
            " [11.04238224]\n",
            " [11.05589294]\n",
            " [10.91339779]\n",
            " [10.92568016]\n",
            " [10.82463837]\n",
            " [10.64651871]\n",
            " [10.80989742]\n",
            " [10.85811806]\n",
            " [10.6084404 ]\n",
            " [10.1348753 ]\n",
            " [10.27707005]\n",
            " [10.15514469]\n",
            " [10.42017746]\n",
            " [10.47852993]\n",
            " [10.4168005 ]\n",
            " [10.59431076]\n",
            " [10.79607964]\n",
            " [10.76229858]\n",
            " [10.77826786]\n",
            " [10.70671177]\n",
            " [10.70302582]\n",
            " [10.58171463]\n",
            " [10.47822475]\n",
            " [10.40758991]\n",
            " [10.38148594]\n",
            " [10.38271141]\n",
            " [10.28996658]\n",
            " [10.15913486]\n",
            " [10.20827579]\n",
            " [10.32282639]\n",
            " [10.20888996]\n",
            " [10.05656147]\n",
            " [10.19138432]\n",
            " [10.37595367]\n",
            " [10.51569271]\n",
            " [10.7702837 ]\n",
            " [10.84122467]\n",
            " [10.76168251]\n",
            " [10.75339222]\n",
            " [10.64897633]\n",
            " [10.75277805]\n",
            " [10.63454247]\n",
            " [10.69350433]\n",
            " [10.73558331]\n",
            " [10.64897633]\n",
            " [10.64620972]\n",
            " [10.6750803 ]\n",
            " [10.73189354]\n",
            " [10.66371822]\n",
            " [10.64344692]\n",
            " [10.45703411]\n",
            " [10.23591614]\n",
            " [10.32313442]\n",
            " [10.43768501]\n",
            " [10.4579525 ]\n",
            " [10.29488277]\n",
            " [10.26969337]\n",
            " [10.2018261 ]\n",
            " [10.34278774]]\n",
            "99/99 [==============================] - 3s 2ms/step - loss: 0.0879\n",
            "correct prediction: price is going up - BUY NOW\n",
            "BUY NOW!!!!!!!!!!!!!!!!!! 1.0\n",
            "UP PRED j\n",
            "NEW PRED COMBINED N\n",
            "COMBO Correct UP LSTM, XGBOOST, COMBINED                        0 1 0\n",
            "COMBO Correct Down LSTM, XGBOOST, COMBINED                      1 0 0\n",
            "COMBO Incorrect Pred UP Actual Down LSTM, XGBOOST, COMBINED     0 0 0\n",
            "COMBO Incorrect Pred Down Actual Up LSTM, XGBOOST, COMBINED     0 0 1\n",
            "COMBINED PERCENTAGE CORRECT LSTM, XGBOOST, COMBINED 100.0   100.0   0.0\n",
            "---------------------END-----------------------------\n",
            "LSTM PREDICTION NOT SCALED      [[10.4579525]]\n",
            "XGBOOST PREDICTION NOT SCALED   [10.41622]\n",
            "--------------------------------------------------\n",
            "DATASET 3!!! [[10.12136364]\n",
            " [10.17418575]\n",
            " [10.25741291]\n",
            " [10.24912071]\n",
            " [10.3225174 ]\n",
            " [10.51692009]\n",
            " [10.49204159]\n",
            " [10.57742119]\n",
            " [10.61611271]\n",
            " [10.70210552]\n",
            " [10.46163845]\n",
            " [10.40605354]\n",
            " [10.21687508]\n",
            " [10.03384113]\n",
            " [10.36336231]\n",
            " [10.48467159]\n",
            " [10.55991364]\n",
            " [10.54025936]\n",
            " [10.32190609]\n",
            " [10.42079163]\n",
            " [10.59615231]\n",
            " [10.57434654]\n",
            " [10.54732132]\n",
            " [10.64129829]\n",
            " [10.80652332]\n",
            " [10.90848255]\n",
            " [10.99938488]\n",
            " [10.8882103 ]\n",
            " [10.95915508]\n",
            " [11.03071213]\n",
            " [11.05282307]\n",
            " [11.15201664]\n",
            " [11.00368404]\n",
            " [10.76598358]\n",
            " [10.39898968]\n",
            " [10.52214146]\n",
            " [10.53012276]\n",
            " [10.69227695]\n",
            " [10.84736729]\n",
            " [10.72759342]\n",
            " [10.81389141]\n",
            " [11.04238224]\n",
            " [11.05589294]\n",
            " [10.91339779]\n",
            " [10.92568016]\n",
            " [10.82463837]\n",
            " [10.64651871]\n",
            " [10.80989742]\n",
            " [10.85811806]\n",
            " [10.6084404 ]\n",
            " [10.1348753 ]\n",
            " [10.27707005]\n",
            " [10.15514469]\n",
            " [10.42017746]\n",
            " [10.47852993]\n",
            " [10.4168005 ]\n",
            " [10.59431076]\n",
            " [10.79607964]\n",
            " [10.76229858]\n",
            " [10.77826786]\n",
            " [10.70671177]\n",
            " [10.70302582]\n",
            " [10.58171463]\n",
            " [10.47822475]\n",
            " [10.40758991]\n",
            " [10.38148594]\n",
            " [10.38271141]\n",
            " [10.28996658]\n",
            " [10.15913486]\n",
            " [10.20827579]\n",
            " [10.32282639]\n",
            " [10.20888996]\n",
            " [10.05656147]\n",
            " [10.19138432]\n",
            " [10.37595367]\n",
            " [10.51569271]\n",
            " [10.7702837 ]\n",
            " [10.84122467]\n",
            " [10.76168251]\n",
            " [10.75339222]\n",
            " [10.64897633]\n",
            " [10.75277805]\n",
            " [10.63454247]\n",
            " [10.69350433]\n",
            " [10.73558331]\n",
            " [10.64897633]\n",
            " [10.64620972]\n",
            " [10.6750803 ]\n",
            " [10.73189354]\n",
            " [10.66371822]\n",
            " [10.64344692]\n",
            " [10.45703411]\n",
            " [10.23591614]\n",
            " [10.32313442]\n",
            " [10.43768501]\n",
            " [10.4579525 ]\n",
            " [10.29488277]\n",
            " [10.26969337]\n",
            " [10.2018261 ]\n",
            " [10.34278774]\n",
            " [10.28812313]]\n",
            "100/100 [==============================] - 3s 3ms/step - loss: 0.0699\n",
            "BUY NOW!!!!!!!!!!!!!!!!!! 0.5\n",
            "UP PRED j\n",
            "NEW PRED COMBINED d\n",
            "COMBO Correct UP LSTM, XGBOOST, COMBINED                        0 1 0\n",
            "COMBO Correct Down LSTM, XGBOOST, COMBINED                      2 1 1\n",
            "COMBO Incorrect Pred UP Actual Down LSTM, XGBOOST, COMBINED     0 0 0\n",
            "COMBO Incorrect Pred Down Actual Up LSTM, XGBOOST, COMBINED     0 0 1\n",
            "COMBINED PERCENTAGE CORRECT LSTM, XGBOOST, COMBINED 100.0   100.0   50.0\n",
            "---------------------END-----------------------------\n",
            "LSTM PREDICTION NOT SCALED      [[10.498842]]\n",
            "XGBOOST PREDICTION NOT SCALED   [10.216585]\n",
            "--------------------------------------------------\n",
            "dataset3 LAST POINT [0]\n",
            "x_train LAST POINT [1]\n",
            "[0]\n",
            "correct prediction Pred Down and Actual Down\n",
            "PERCENTAGE CORRECT 100.0\n",
            "I 0\n",
            "Correct UP                      0\n",
            "Correct Down                    1\n",
            "Incorrect Pred UP Actual Down   0\n",
            "Incorrect Pred Down Actual Up   0\n",
            "---------------------------------------------------------\n",
            "Prediction, Actual Result [0] [0]\n",
            "---------------------------------------------------------\n",
            "dataset3 LAST POINT [1]\n",
            "x_train LAST POINT [0]\n",
            "[1]\n",
            "correct prediction Pred UP and Actual Up\n",
            "PERCENTAGE CORRECT 100.0\n",
            "I 1\n",
            "Correct UP                      1\n",
            "Correct Down                    1\n",
            "Incorrect Pred UP Actual Down   0\n",
            "Incorrect Pred Down Actual Up   0\n",
            "---------------------------------------------------------\n",
            "Prediction, Actual Result [1] [1]\n",
            "---------------------------------------------------------\n",
            "<class 'pandas.core.series.Series'>\n",
            "0      10.121364\n",
            "1      10.174186\n",
            "2      10.257413\n",
            "3      10.249121\n",
            "4      10.322517\n",
            "         ...    \n",
            "495    16.165047\n",
            "496    16.090687\n",
            "497    16.116709\n",
            "498    15.894560\n",
            "499    15.958381\n",
            "Name: Adj Close, Length: 500, dtype: float64\n",
            "DATA RANGE 500\n",
            "[16.11670876]\n",
            "PREDICTION [16.11670876]\n",
            "DAY BEFORE 15.894559860229492\n",
            "Actual outcome  15.958380699157715\n",
            "Correct Price is going up\n",
            "PERCENTAGE CORRECT 100.0\n",
            "Correct UP                        1\n",
            "Correct Down                      0\n",
            "Incorrect Pred UP Actual Down     0\n",
            "Incorrect Pred Down Actual Up     0\n",
            "0      10.121364\n",
            "1      10.174186\n",
            "2      10.257413\n",
            "3      10.249121\n",
            "4      10.322517\n",
            "         ...    \n",
            "496    16.090687\n",
            "497    16.116709\n",
            "498    15.894560\n",
            "499    15.958381\n",
            "500    15.788904\n",
            "Name: Adj Close, Length: 501, dtype: float64\n",
            "DATA RANGE 501\n",
            "[15.89455986]\n",
            "PREDICTION [15.89455986]\n",
            "DAY BEFORE 15.958380699157715\n",
            "Actual outcome  15.788904190063475\n",
            "Correct Price is going down\n",
            "PERCENTAGE CORRECT 100.0\n",
            "Correct UP                        1\n",
            "Correct Down                      1\n",
            "Incorrect Pred UP Actual Down     0\n",
            "Incorrect Pred Down Actual Up     0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0      10.121364\n",
            "1      10.174186\n",
            "2      10.257413\n",
            "3      10.249121\n",
            "4      10.322517\n",
            "         ...    \n",
            "495    16.165047\n",
            "496    16.090687\n",
            "497    16.116709\n",
            "498    15.894560\n",
            "499    15.958381\n",
            "Name: Adj Close, Length: 500, dtype: float64\n",
            "DATA RANGE 500\n",
            "498    16.116709\n",
            "dtype: float64\n",
            "PREDICTION 498    16.116709\n",
            "dtype: float64\n",
            "DAY BEFORE TRAINING 15.894559860229492\n",
            "Actual outcome  15.958380699157715\n",
            "['498', '16.116709', 'dtype:', 'float64']\n",
            "16.116709\n",
            "16.116709\n",
            "Correct Price is going up\n",
            "PERCENTAGE CORRECT 100.0\n",
            "Correct UP                        1\n",
            "Correct Down                      0\n",
            "Incorrect Pred UP Actual Down     0\n",
            "Incorrect Pred Down Actual Up     0\n",
            "0      10.121364\n",
            "1      10.174186\n",
            "2      10.257413\n",
            "3      10.249121\n",
            "4      10.322517\n",
            "         ...    \n",
            "496    16.090687\n",
            "497    16.116709\n",
            "498    15.894560\n",
            "499    15.958381\n",
            "500    15.788904\n",
            "Name: Adj Close, Length: 501, dtype: float64\n",
            "DATA RANGE 501\n",
            "499    15.89456\n",
            "dtype: float64\n",
            "PREDICTION 499    15.89456\n",
            "dtype: float64\n",
            "DAY BEFORE TRAINING 15.958380699157715\n",
            "Actual outcome  15.788904190063475\n",
            "['499', '15.89456', 'dtype:', 'float64']\n",
            "15.89456\n",
            "15.89456\n",
            "Correct Price is going down\n",
            "PERCENTAGE CORRECT 100.0\n",
            "Correct UP                        1\n",
            "Correct Down                      1\n",
            "Incorrect Pred UP Actual Down     0\n",
            "Incorrect Pred Down Actual Up     0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9k5sv6LSTSu"
      },
      "source": [
        "# dfStock = pd.read_csv('APPL.csv') \n",
        "# # dfStock = pd.read_csv('AFSI.csv') \n",
        "# dfStock = pd.read_csv('AIRR.csv')\n",
        "# dfStock.shape\n",
        "# dfStock1 = pd.read_csv('APPL.csv')\n",
        "# #Adj closing\n",
        "\n",
        "# #converting to numpy array\n",
        "\n",
        "\n",
        "# # dfStockClose = dfStock.filter(['Adj Close'])\n",
        "\n",
        "# # dataset = dfStockClose.values\n",
        "# # lenData = len(dataset)\n",
        "\n",
        "# AllData = [dfStock, dfStock1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-afeaUPSbII"
      },
      "source": [
        "# def RunData(AllData, iterN):\n",
        "#   num = 0\n",
        "#   # dataMin = DataMin\n",
        "#   # dataMax = DataMax\n",
        "#   iter = iterN\n",
        "#   for i in AllData:\n",
        "    \n",
        "#     #dataIter = AllData[i]\n",
        "#     LSTMandQgBoostPred(i, iter, num )\n",
        "#     num = num + 1\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#       # writefile.write(\"DfStock\" + j + '\\n' )\n",
        "      \n",
        "#       #ESM(d, num, dataMin, dataMax ) NOT WORKING!!!\n",
        "   \n",
        "#       #ARIMA(d, num, dataMin, dataMax, iter)\n",
        "\n",
        "    \n",
        "      # DecisionTree(d) \n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWqq9_R1CwNe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0uvbM_LSc6I"
      },
      "source": [
        "RunData(AllData, 2 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2K_bIT4SU3u"
      },
      "source": [
        "\n",
        "def LSTMandQgBoostPred(datasets, iter, name ):\n",
        "  dfStockCloses = datasets.filter(['Adj Close'])\n",
        "  datasetNew = dfStockCloses.values\n",
        "\n",
        "\n",
        "\n",
        "  print('DATASET NEWW!!!', datasetNew)\n",
        "\n",
        "  lenData = len(datasetNew)\n",
        "  dataset1 = datasetNew[900:1000]\n",
        "  lenData1 = len(dataset1)\n",
        "  RESULTS = []\n",
        "  RESULTSXGBOOST = []\n",
        "  RESULTSCOMBINED = []\n",
        "\n",
        "  totalLSTM = 1\n",
        "  totalXGBOOST = 1\n",
        "  totalCombo = 1\n",
        "  # print('Length of DATASET1', lenData1)\n",
        "  # print('Length of DATASET1', lenData1)\n",
        "  percentageLSTM = 0.0\n",
        "  percentageXGBOOST = 0.0\n",
        "  percentageCombo = 0.0\n",
        "  NewPred = 'N'\n",
        "  \n",
        "  \n",
        "  for i in range(iter):\n",
        "\n",
        "    \n",
        "    dataRange = lenData1 + i\n",
        "    dataset3 = datasetNew[0:dataRange, ]\n",
        "    # print('Length of DATASET3', len(dataset3))\n",
        "    # print('dataset', dataset3)\n",
        "  \n",
        "\n",
        "    #training rows\n",
        "    \n",
        "    training_data_len = len(dataset3) #- 1\n",
        "      \n",
        "    training_data_len\n",
        "    #Scale the data\n",
        "    #///////////////MIN MAX SCALER///////////\n",
        "    # scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    # scaled_data = scaler.fit_transform(dataset3)\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_dataXGBOOST = dataset3\n",
        "    print('DATASET 3!!!', dataset3)\n",
        "    scaled_data = scaler.fit_transform(dataset3)\n",
        "\n",
        "    #//////////////STANDARD SCALER////////\n",
        "    # scaler = StandardScaler()\n",
        "    # #scaled_data = scaler.fit(dataset3)\n",
        "    # scaled_data = scaler.fit_transform(dataset3)\n",
        "    # scaled_data = scaler.transform([[0, 10]])\n",
        "\n",
        "   # scaled_data = preprocessing.normalize(dataset3)\n",
        "   \n",
        "\n",
        "    #create training dataset\n",
        "    train_data = scaled_data[0:training_data_len, :]\n",
        "    train_dataXGBOOST = scaled_dataXGBOOST\n",
        "    # print('Length of TRAIN_DATA', len(train_data))\n",
        "    # split the data x y train\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    x_trainXGBOOST = []\n",
        "    y_trainXGBOOST = []\n",
        "\n",
        "    # rangeOfData =len(train_data)\n",
        "    for j in range(1, len(train_data)):\n",
        "        x_train.append(train_data[j-1 : j, 0])\n",
        "        y_train.append(train_data[j,0])\n",
        "        x_trainXGBOOST.append(train_dataXGBOOST[j-1 : j, 0])\n",
        "        y_trainXGBOOST.append(train_dataXGBOOST[j,0])\n",
        "    # print('Length of XTRAIN', len(x_train))\n",
        "    # convert x y train to numpy array\n",
        "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "    x_trainXGBOOST, y_trainXGBOOST = np.array(x_trainXGBOOST), np.array(y_trainXGBOOST)\n",
        "  #Reshape the data\n",
        "    \n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "    x_train.shape\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50,return_sequences=True, input_shape = (x_train.shape[1], 1)))\n",
        "    model.add(LSTM(50,return_sequences=False))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(optimizer='adam', loss = 'mean_squared_error')\n",
        "    # model.compile(optimizer='adam', loss = 'mean_squared_error')\n",
        "    model.fit(x_train, y_train, batch_size=1, epochs=1)\n",
        "    #Testing set\n",
        "    test_data =scaled_data[-1]\n",
        "    test_dataXGBOOST = scaled_dataXGBOOST[-1]\n",
        "    # print('test data before prediction', test_data)\n",
        "    x_test = []\n",
        "    y_test = dataset3[-1] #actual last value for prediction\n",
        "    x_testXGBOOST = []\n",
        "    y_testXGBOOST = dataset3[-1]\n",
        "    # print('y_test before prediction', y_test)\n",
        "    x_test.append(test_data)\n",
        "    x_testXGBOOST.append(test_dataXGBOOST)\n",
        "    x_test = np.array(x_test)\n",
        "    x_testXGBOOST = np.array(x_testXGBOOST)\n",
        "    x_test = np.reshape(x_test, (1, 1, 1))\n",
        "  #Predictions\n",
        "    predictions = model.predict(x_test)\n",
        "    predictionsNotScaled = scaler.inverse_transform(predictions)\n",
        "    predictionsNotScaled = predictionsNotScaled \n",
        "  # #RMSE\n",
        "  #   rmse = np.sqrt(np.mean(predictionsNotScaled - y_test)**2)\n",
        "  #   print(rmse)\n",
        "  \n",
        "    \n",
        "    upPred = 'j'\n",
        "    downPred = 'h'\n",
        "    upActual = 'g'\n",
        "    downActual = 'z'\n",
        "    spread = 1.05\n",
        "    dayBefore = dataset3[-2] * spread\n",
        "\n",
        "    if predictionsNotScaled > dayBefore:\n",
        "      upPred = 'x'\n",
        "    \n",
        "    if predictionsNotScaled < dayBefore:\n",
        "      downPred = 'y'\n",
        "    if y_test > dayBefore:\n",
        "      upActual = 'x'\n",
        "    if y_test < dayBefore:\n",
        "      downActual = 'y'\n",
        "    if upPred == upActual:\n",
        "      # print('Correct price is going UP')\n",
        "      predCorrect = 1\n",
        "      pass\n",
        "    if downPred == downActual:\n",
        "      # print('Correct price is going DOWN')\n",
        "      predCorrect = 2\n",
        "      \n",
        "      pass\n",
        "    if upPred == 'x' and downActual == 'y':\n",
        "      # print('Wrong Prediction')\n",
        "      predCorrect = 3\n",
        "      pass\n",
        "\n",
        "    if downPred == 'y' and upActual == 'x':\n",
        "      # print('Wrong Prediction')\n",
        "      predCorrect = 4\n",
        "      pass\n",
        "    \n",
        "    \n",
        "    RESULTS.append(predCorrect)\n",
        "    # print(RESULTS)\n",
        "    onesLSTM=  RESULTS.count(1)\n",
        "    twosLSTM = RESULTS.count(2)\n",
        "    zerosLSTM = RESULTS.count(3)\n",
        "    foursLSTM = RESULTS.count(4)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "      # print('Result RATIO',RATIO)\n",
        "    totalCorrectLSTM = twosLSTM + onesLSTM\n",
        "    totalLSTM = totalCorrectLSTM + zerosLSTM + foursLSTM\n",
        "   \n",
        "    percentageLSTM = (100/totalLSTM) * totalCorrectLSTM\n",
        "    \n",
        "      # print('/////////////////////////////////////////')\n",
        "    #   print('PERCENAGE', percentageLSTM)\n",
        "    # print(onesLSTM)\n",
        "    # print(twosLSTM)\n",
        "    # print(zerosLSTM)\n",
        "    # print(foursLSTM)\n",
        "\n",
        "# XG BOOST ---------------------------------------------------XG BOOST\n",
        "    \n",
        "    xgbr = XBGRegressor(verbosity = 0)\n",
        "    # print(xgbr)\n",
        "\n",
        "    xgbr.fit(x_trainXGBOOST, y_trainXGBOOST)\n",
        "\n",
        "    score = xgbr.score(x_trainXGBOOST, y_trainXGBOOST)\n",
        "    # print(\"Training Score\", score)\n",
        "\n",
        "    ypred = xgbr.predict(x_testXGBOOST)\n",
        "    # print('i', i)\n",
        "\n",
        "\n",
        "    RealDataBL = dataset3[-2] \n",
        "    Prediction = ypred #* 1.0001\n",
        "    # print('YPRED AFTER CHANGE', Prediction)\n",
        "    RealDataLast = dataset3[-1]\n",
        "\n",
        "    PredUp = -1\n",
        "    PredDown = -2\n",
        "    RealUp= -3\n",
        "    RealDown = -4\n",
        "    # Checking if prediction showed price going up or down\n",
        "\n",
        "    if Prediction > RealDataBL:\n",
        "        PredUp = 1\n",
        "        \n",
        "    if Prediction < RealDataBL:\n",
        "        PredDown = 0\n",
        "        \n",
        "    # Checking if price has actually gone up or down \n",
        "        \n",
        "    if RealDataLast > RealDataBL:\n",
        "        RealUp = 1\n",
        "\n",
        "    if RealDataLast < RealDataBL:\n",
        "        RealDown = 0\n",
        "        \n",
        "    if PredUp == RealUp:\n",
        "        print(\"correct prediction: price is going up - BUY NOW\")\n",
        "        Result = 1\n",
        "        \n",
        "    if PredDown == RealDown:\n",
        "        # print(\"correct prediction: price is going down\")\n",
        "        Result = 2\n",
        "        \n",
        "    if PredUp == 1 and RealDown == 0:\n",
        "        # print(\"INcorrect prediction\")\n",
        "        Result = 3\n",
        "        \n",
        "    if PredDown == 0 and RealUp == 1:\n",
        "        # print(\"INcorrect prediction\")\n",
        "        Result = 4\n",
        "\n",
        "\n",
        "\n",
        "    #PRED RESULTS----------------------------\n",
        "    RESULTSXGBOOST.append(Result)\n",
        "    # print(RESULTS)\n",
        "    ones=  RESULTSXGBOOST.count(1)\n",
        "    twos = RESULTSXGBOOST.count(2)\n",
        "    threes = RESULTSXGBOOST.count(3)\n",
        "    fours = RESULTSXGBOOST.count(4)\n",
        "   \n",
        "    \n",
        "    \n",
        "    \n",
        "      # print('Result RATIO',RATIO)\n",
        "    totalCorrectXGBOOST = ones + twos\n",
        "    totalXGBOOST = totalCorrectXGBOOST + threes + fours\n",
        "\n",
        "    percentageXGBOOST = (100/totalXGBOOST) * totalCorrectXGBOOST\n",
        "    buyNow = ones/totalXGBOOST\n",
        "    print('BUY NOW!!!!!!!!!!!!!!!!!!', buyNow)\n",
        "# DECISION TREE -----------------------------------------------\n",
        "    \n",
        "# COMBO PREDICTIONS -----------------------------------------------\n",
        "    print('UP PRED', upPred)\n",
        "    print('NEW PRED COMBINED', NewPred)\n",
        "\n",
        "    if PredUp == 1 and upPred == 'x':\n",
        "      NewPred = 'u'\n",
        "\n",
        "    if PredDown == 0 and downPred == 'y':\n",
        "      NewPred = 'd'\n",
        "\n",
        "    if PredUp == 1 and downPred == 'y':\n",
        "      NewPred ='d'\n",
        "    \n",
        "    if PredUp == 0 and upPred == 'x':\n",
        "      NewPred = 'u'\n",
        "\n",
        "            \n",
        "    if NewPred == 'u' and RealUp == 1:\n",
        "        # print(\"correct prediction: price is going up\")\n",
        "        ResultCombo = 1\n",
        "        \n",
        "    if NewPred == 'd' and RealDown == 0:\n",
        "        # print(\"correct prediction: price is going down\")\n",
        "        ResultCombo = 2\n",
        "        \n",
        "    if NewPred == 'u' and RealDown == 0:\n",
        "        # print('Incorrect Pred UP Actual Down')\n",
        "        ResultCombo = 3\n",
        "        \n",
        "    if NewPred == 'd' and RealUp == 1:\n",
        "        # print('Incorrect Pred Down Actual Up',)\n",
        "        ResultCombo = 4\n",
        "\n",
        "     #COMBO PRED RESULTS--------------------------------------------------------\n",
        "    RESULTSCOMBINED.append(ResultCombo)\n",
        "    # print(RESULTS)\n",
        "    onesCombo=  RESULTSCOMBINED.count(1)\n",
        "    twosCombo = RESULTSCOMBINED.count(2)\n",
        "    threesCombo = RESULTSCOMBINED.count(3)\n",
        "    foursCombo = RESULTSCOMBINED.count(4)\n",
        "    print('COMBO Correct UP LSTM, XGBOOST, COMBINED                       ',onesLSTM,ones,onesCombo)\n",
        "    print('COMBO Correct Down LSTM, XGBOOST, COMBINED                     ', twosLSTM,twos,twosCombo)\n",
        "    print('COMBO Incorrect Pred UP Actual Down LSTM, XGBOOST, COMBINED    ',zerosLSTM,threes,threesCombo)\n",
        "    print('COMBO Incorrect Pred Down Actual Up LSTM, XGBOOST, COMBINED    ', foursLSTM,fours,foursCombo)\n",
        "    \n",
        "    # if i > 0 and threesCombo > 0 and foursCombo > 0 :\n",
        "   \n",
        "        # print('Result RATIO',RATIO)\n",
        "    totalCorrectCombo = onesCombo + twosCombo\n",
        "    totalCombo = totalCorrectCombo + threesCombo + foursCombo\n",
        "\n",
        "    percentageCombo = (100/totalCombo) * totalCorrectCombo\n",
        "    print('COMBINED PERCENTAGE CORRECT LSTM, XGBOOST, COMBINED', percentageLSTM,' ',percentageXGBOOST,' ',percentageCombo)\n",
        "\n",
        "\n",
        "    print('---------------------END-----------------------------')\n",
        "\n",
        "    print('LSTM PREDICTION NOT SCALED     ',predictionsNotScaled)\n",
        "    print('XGBOOST PREDICTION NOT SCALED  ',Prediction)\n",
        "    print('--------------------------------------------------')\n",
        "  ones = str(ones)\n",
        "  twos = str(twos)\n",
        "  threes = str(threes)\n",
        "  fours = str(fours)\n",
        "  onesLSTM = str(onesLSTM)\n",
        "  twosLSTM = str(twosLSTM)\n",
        "  zerosLSTM = str(zerosLSTM)\n",
        "  foursLSTM = str(foursLSTM)\n",
        "  \n",
        "  with open('/content/EX1.txt', 'a') as writefile:\n",
        "    writefile.write(\"DfStock\" + ' ' + name + ' ' + 'XGB' '\\n' )\n",
        "    writefile.write(ones + '\\n')\n",
        "    writefile.write(twos + '\\n')\n",
        "    writefile.write(threes + '\\n')\n",
        "    writefile.write(fours + '\\n')\n",
        "    \n",
        "    writefile.write(\"DfStock\" + ' ' + name + ' ' + 'LSTM' '\\n' )\n",
        "    writefile.write(onesLSTM + '\\n')\n",
        "    writefile.write(twosLSTM + '\\n')\n",
        "    writefile.write(zerosLSTM + '\\n')\n",
        "    writefile.write(foursLSTM + '\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5QI6A7xmo3z"
      },
      "source": [
        "def DecisionTree(datasetDF, iter, name):\n",
        "\n",
        "  datasetDF['Price_Up'] = np.where(datasetDF['Close'].shift(-1) > datasetDF['Close'], 1, 0)\n",
        "  dfStockClose = datasetDF.filter(['Price_Up'])\n",
        "  dataset = dfStockClose.values\n",
        "  lenData = len(dataset)\n",
        "  dataset1 = dataset[900:1000] #training\n",
        "  lenData1 = len(dataset1)\n",
        "  \n",
        "\n",
        "  #ORIGINAL ---------------------\n",
        "  # dataset3 = dataset[:2002]\n",
        "  # print('dataset3', dataset3[2001])\n",
        "#--------------------------------------\n",
        "  RESULTS = []\n",
        "  for i in range(iter):\n",
        "\n",
        "    dataRange = lenData1 + i\n",
        "    dataset3 = dataset[0:dataRange, ]\n",
        "    # print('Length of DATASET3', len(dataset3))\n",
        "    scaled_data = dataset3\n",
        "    print('dataset3 LAST POINT', scaled_data[-1])\n",
        "    dataset3 = dataset[0:dataRange, ]\n",
        "    # print('dataset', dataset3)\n",
        "    training_data_len = len(dataset3) #- 1\n",
        "    \n",
        "    training_data_len\n",
        "            #create training dataset\n",
        "    scaled_data = dataset3\n",
        "    train_data = scaled_data\n",
        "    # print('Length of TRAIN_DATA', len(train_data))\n",
        "            # split the data x y train\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    for j in range(1, len(train_data)):\n",
        "            x_train.append(train_data[j-1 : j, 0])\n",
        "            y_train.append(train_data[j,0])\n",
        "\n",
        "    # print('Length of XTRAIN', len(x_train))\n",
        "    # convert x y train to numpy array\n",
        "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "    print('x_train LAST POINT', x_train[-1])\n",
        "    #Reshape the data\n",
        "\n",
        "    #x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "    x_train.shape\n",
        "\n",
        "    #-------- in lstm the layers would go below -----------7\n",
        "\n",
        "    #Testing set\n",
        "    test_data =scaled_data[-1]\n",
        "    # print('test data before prediction', test_data)\n",
        "    x_test = []\n",
        "    y_test = test_data #actual last value for prediction\n",
        "    # print('y_test before prediction', y_test)\n",
        "    x_test.append(test_data)\n",
        "    x_test = np.array(x_test)\n",
        "\n",
        "    tree= DecisionTreeClassifier().fit(x_train, y_train)\n",
        "    tree_predictions = tree.predict(x_test)\n",
        "    print(tree_predictions)\n",
        "\n",
        "\n",
        "    if tree_predictions == 1 and  dataset3[-1] == 1:\n",
        "      print('correct prediction Pred UP and Actual Up')\n",
        "      CorrectPred = 1\n",
        "\n",
        "    if tree_predictions == 0 and dataset3[-1] == 0:\n",
        "      print('correct prediction Pred Down and Actual Down')\n",
        "      CorrectPred = 2\n",
        "\n",
        "    if tree_predictions == 1 and dataset3[-1] == 0:\n",
        "      print('incorrect prediction Pred Up Actual Down')\n",
        "      CorrectPred = 3\n",
        "    \n",
        "    if tree_predictions == 0 and dataset3[-1] == 1:\n",
        "      print('incorrect prediction pred Down and Actual Up')\n",
        "      CorrectPred = 4\n",
        "\n",
        "        #PRED RESULTS----------------------------\n",
        "    RESULTS.append(CorrectPred)\n",
        "    # print(RESULTS)\n",
        "    onesDT=  RESULTS.count(1)\n",
        "    twosDT = RESULTS.count(2)\n",
        "    threesDT = RESULTS.count(3)\n",
        "    foursDT = RESULTS.count(4)\n",
        "   \n",
        "    \n",
        "    # if i > 0 and threes > 0 and fours > 0 :\n",
        "    MoreThanZero = threesDT + foursDT\n",
        "    \n",
        "    if MoreThanZero > 0:\n",
        "\n",
        "      RATIO = (onesDT + twosDT)/ MoreThanZero\n",
        "        # print('Result RATIO',RATIO)\n",
        "      totalCorrectDT = onesDT + twosDT\n",
        "      totalDT = totalCorrectDT + threesDT + foursDT\n",
        "\n",
        "      percentageDT = (100/totalDT) * totalCorrectDT\n",
        "      print('PERCENTAGE CORRECT', percentageDT)\n",
        "        # print('/////////////////////////////////////////')\n",
        "    else:\n",
        "      MoreThanZero = 1\n",
        "      RATIO = (onesDT + twosDT)/ MoreThanZero\n",
        "        # print('Result RATIO',RATIO)\n",
        "      totalCorrectDT = onesDT + twosDT\n",
        "      totalDT = totalCorrectDT + threesDT + foursDT\n",
        "\n",
        "      percentageDT = (100/totalDT) * totalCorrectDT\n",
        "      print('PERCENTAGE CORRECT', percentageDT)\n",
        "        \n",
        "    print('I', i) \n",
        "    print('Correct UP                     ', onesDT)\n",
        "    print('Correct Down                   ', twosDT)\n",
        "    print('Incorrect Pred UP Actual Down  ', threesDT)\n",
        "    print('Incorrect Pred Down Actual Up  ', foursDT)\n",
        "\n",
        "    print('---------------------------------------------------------')\n",
        "    print('Prediction, Actual Result', tree_predictions, dataset3[-1])\n",
        "    print('---------------------------------------------------------')\n",
        "\n",
        "  onesDT = str(onesDT)\n",
        "  twosDT = str(twosDT)\n",
        "  threesDT = str(threesDT)\n",
        "  foursDT = str(foursDT)\n",
        " \n",
        "  \n",
        "  with open('/content/EX1.txt', 'a') as writefile:\n",
        "    writefile.write(\"DfStock\" + ' '  + name + ' ' + 'DTC' '\\n' )\n",
        "    writefile.write(onesDT + '\\n')\n",
        "    writefile.write(twosDT + '\\n')\n",
        "    writefile.write(threesDT + '\\n')\n",
        "    writefile.write(foursDT + '\\n')    \n",
        "  \n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0HycyTLK60N"
      },
      "source": [
        "def ARIMA(datasetDF, iter, name):\n",
        "  datasetDF = datasetDF.filter(['Adj Close'])\n",
        "  #converting to numpy array\n",
        "  time_series = datasetDF['Adj Close']\n",
        "\n",
        "  print(type(time_series))\n",
        "  time_series.rolling(7).mean().plot()\n",
        "  time_series.plot()\n",
        "\n",
        "\n",
        "  dataset1 = time_series[900:1000] #training\n",
        "  lenData1 = len(dataset1)\n",
        "  RESULTS = []\n",
        "  for i in range(iter):\n",
        "\n",
        "    dataRange = lenData1 + i\n",
        "    dataset3 = time_series[0:dataRange, ]\n",
        "      # print('Length of DATASET3', len(dataset3))\n",
        "    print(dataset3)\n",
        "    training_data_length = dataRange - 2\n",
        "    training_data = time_series[:training_data_length]\n",
        "    print('DATA RANGE', dataRange)\n",
        "    NewDataRange = dataRange - 1\n",
        "    test_data = dataset3[NewDataRange]\n",
        "  #Model\n",
        "    model = auto_arima(y = training_data, seasonal=True)\n",
        "    predictions = model.predict(n_periods = 1)\n",
        "    print(predictions)\n",
        "\n",
        "    \n",
        "    print('PREDICTION', predictions)\n",
        "    print('DAY BEFORE', dataset3[training_data_length] )\n",
        "    print('Actual outcome ', dataset3[NewDataRange])\n",
        "\n",
        "    if predictions > dataset3[training_data_length]:\n",
        "      \n",
        "      UpDownPred = 1\n",
        "\n",
        "    if predictions < dataset3[training_data_length]:\n",
        "      \n",
        "      UpDownPred = 0\n",
        "\n",
        "    if dataset3[NewDataRange] > dataset3[training_data_length]:\n",
        "      UpDownActual = 1\n",
        "\n",
        "    if dataset3[NewDataRange] < dataset3[training_data_length]:\n",
        "      UpDownActual = 0\n",
        "\n",
        "    if UpDownPred == 1 and UpDownActual == 1:\n",
        "      print('Correct Price is going up')\n",
        "      ResultSmooth = 1\n",
        "\n",
        "    if UpDownPred == 0 and UpDownActual == 0:\n",
        "      print('Correct Price is going down')\n",
        "      ResultSmooth = 2\n",
        "\n",
        "    if UpDownPred == 1 and UpDownActual == 0:\n",
        "      print('Incorrect Pred UP Actual DOWN')\n",
        "      ResultSmooth = 3\n",
        "\n",
        "    if UpDownPred == 0 and UpDownActual == 1:\n",
        "      print('Incorrect Pred DOWN Actual UP')\n",
        "      ResultSmooth = 4\n",
        "\n",
        "    RESULTS.append(ResultSmooth)\n",
        "      # print(RESULTS)\n",
        "    ones=  RESULTS.count(1)\n",
        "    twos = RESULTS.count(2)\n",
        "    threes = RESULTS.count(3)\n",
        "    fours = RESULTS.count(4)\n",
        "      \n",
        "    totalCorrect = ones + twos\n",
        "    total = totalCorrect + threes + fours\n",
        "\n",
        "    percentage = (100/total) * totalCorrect\n",
        "    print('PERCENTAGE CORRECT', percentage)\n",
        "    print('Correct UP                       ', ones)\n",
        "    print('Correct Down                     ', twos)\n",
        "    print('Incorrect Pred UP Actual Down    ', threes)\n",
        "    print('Incorrect Pred Down Actual Up    ', fours)\n",
        "\n",
        "  ones = str(ones)\n",
        "  twos = str(twos)\n",
        "  threes = str(threes)\n",
        "  fours = str(fours)\n",
        " \n",
        "  \n",
        "  with open('/content/EX1.txt', 'a') as writefile:\n",
        "    writefile.write(\"DfStock\" + ' '  + name + ' ' + 'ARIMA' '\\n' )\n",
        "    writefile.write(ones + '\\n')\n",
        "    writefile.write(twos + '\\n')\n",
        "    writefile.write(threes + '\\n')\n",
        "    writefile.write(fours + '\\n')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npngKt6O-5DF"
      },
      "source": [
        "\n",
        "def XPS(datasetDF, iter, name):\n",
        "\n",
        "\n",
        "  dfStockClose = datasetDF.filter(['Adj Close'])\n",
        "  #converting to numpy array\n",
        "  time_series = dfStockClose['Adj Close']\n",
        "\n",
        "  print(type(time_series))\n",
        "  time_series.rolling(7).mean().plot()\n",
        "  time_series.plot()\n",
        "\n",
        "\n",
        "  dataset1 = time_series[1500:2000] #training\n",
        "  lenData1 = len(dataset1)\n",
        "  RESULTS = []\n",
        "  for i in range(2):\n",
        "\n",
        "    dataRange = lenData1 + i\n",
        "    dataset3 = time_series[0:dataRange, ]\n",
        "      # print('Length of DATASET3', len(dataset3))\n",
        "    print(dataset3)\n",
        "    training_data_length = dataRange - 2\n",
        "    training_data = time_series[:training_data_length]\n",
        "    print('DATA RANGE', dataRange)\n",
        "    NewDataRange = dataRange - 1\n",
        "    test_data = dataset3[NewDataRange]\n",
        "  #Model\n",
        "    # model = auto_arima(y = training_data, seasonal=True)\n",
        "    model = ExponentialSmoothing(endog= training_data, seasonal_periods = 5).fit()\n",
        "    predictions = model.forecast(steps = 1)\n",
        "    print(predictions)\n",
        "\n",
        "    \n",
        "    print('PREDICTION', predictions)\n",
        "    print('DAY BEFORE TRAINING', dataset3[training_data_length] )\n",
        "    print('Actual outcome ', dataset3[NewDataRange])\n",
        "\n",
        "    predictions = str(predictions)\n",
        "\n",
        "    stripped = predictions.split()\n",
        "    print(stripped)\n",
        "\n",
        "    print(stripped[1])\n",
        "\n",
        "    predictions = float(stripped[1])\n",
        "\n",
        "    print(predictions)\n",
        "    \n",
        "    if predictions > dataset3[training_data_length]:\n",
        "      \n",
        "      UpDownPred = 1\n",
        "\n",
        "    if predictions < dataset3[training_data_length]:\n",
        "      \n",
        "      UpDownPred = 0\n",
        "\n",
        "    if dataset3[NewDataRange] > dataset3[training_data_length]:\n",
        "      UpDownActual = 1\n",
        "\n",
        "    if dataset3[NewDataRange] < dataset3[training_data_length]:\n",
        "      UpDownActual = 0\n",
        "\n",
        "    if UpDownPred == 1 and UpDownActual == 1:\n",
        "      print('Correct Price is going up')\n",
        "      ResultSmooth = 1\n",
        "\n",
        "    if UpDownPred == 0 and UpDownActual == 0:\n",
        "      print('Correct Price is going down')\n",
        "      ResultSmooth = 2\n",
        "\n",
        "    if UpDownPred == 1 and UpDownActual == 0:\n",
        "      print('Incorrect Pred UP Actual DOWN')\n",
        "      ResultSmooth = 3\n",
        "\n",
        "    if UpDownPred == 0 and UpDownActual == 1:\n",
        "      print('Incorrect Pred DOWN Actual UP')\n",
        "      ResultSmooth = 4\n",
        "\n",
        "    RESULTS.append(ResultSmooth)\n",
        "      # print(RESULTS)\n",
        "    ones=  RESULTS.count(1)\n",
        "    twos = RESULTS.count(2)\n",
        "    threes = RESULTS.count(3)\n",
        "    fours = RESULTS.count(4)\n",
        "      \n",
        "    totalCorrect = ones + twos\n",
        "    total = totalCorrect + threes + fours\n",
        "\n",
        "    percentage = (100/total) * totalCorrect\n",
        "    print('PERCENTAGE CORRECT', percentage)\n",
        "    print('Correct UP                       ', ones)\n",
        "    print('Correct Down                     ', twos)\n",
        "    print('Incorrect Pred UP Actual Down    ', threes)\n",
        "    print('Incorrect Pred Down Actual Up    ', fours)\n",
        "\n",
        "  ones = str(ones)\n",
        "  twos = str(twos)\n",
        "  threes = str(threes)\n",
        "  fours = str(fours)\n",
        " \n",
        "  \n",
        "  with open('/content/EX1.txt', 'a') as writefile:\n",
        "    writefile.write(\"DfStock\" + ' '  + name + ' ' + 'XPS' '\\n' )\n",
        "    writefile.write(ones + '\\n')\n",
        "    writefile.write(twos + '\\n')\n",
        "    writefile.write(threes + '\\n')\n",
        "    writefile.write(fours + '\\n')  "
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}